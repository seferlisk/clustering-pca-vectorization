{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure the notebook can find the classes in the src/ folder\n",
    "\n",
    "# Cell 1: Setup and Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project root to the path so we can import our modules\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src import (\n",
    "    DatasetManager, EmbeddingEngine, Clusterer,\n",
    "    ClusterEvaluator, ResultStore, Visualizer\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Task 1: Text Transformation & Embedding Comparison\n",
    "     We will focus on the \"transformation\" phaseâ€”moving from raw text to numerical vectors using our three distinct engines.\n",
    "     Word2Vec and FastText mathematically require the text to be split into a list of words (tokens). Our EmbeddingEngine handles\n",
    "     this internally using .split()"
   ],
   "id": "d43a435d4da8cb7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Task 1: Transform the Data\n",
    "print(\"--- Task 1: Starting Data Transformation ---\")\n",
    "\n",
    "# 1. Initialize  Managers\n",
    "# Ensure 'bbc-text.csv' is in the Datasets folder relative to the project root\n",
    "bbc_path = '../Datasets/bbc_news_test.csv'\n",
    "manager = DatasetManager(bbc_path)\n",
    "embedder = EmbeddingEngine(vector_size=100)\n",
    "\n",
    "# 2. Load the Raw Data\n",
    "# We access the raw 'text' column directly to respect the \"no preprocessing\" constraint\n",
    "datasets = manager.prepare_data()\n",
    "\n",
    "# 3. Transformation & Storage\n",
    "# We will store the results in a dictionary to compare shapes/dimensions\n",
    "embedding_results = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nTransforming {name.upper()} dataset...\")\n",
    "\n",
    "    # Choose the raw text column\n",
    "    # In the BBC dataset, it's usually 'text' or 'Text'\n",
    "    raw_text = df['text'] if 'text' in df.columns else df['Text']\n",
    "\n",
    "    # Generate the 3 types of embeddings\n",
    "    tfidf_vectors = embedder.get_tfidf_embeddings(raw_text)\n",
    "    w2v_vectors   = embedder.get_word2vec_embeddings(raw_text)\n",
    "    ft_vectors    = embedder.get_fasttext_embeddings(raw_text)\n",
    "\n",
    "    embedding_results[name] = {\n",
    "        'TF-IDF': tfidf_vectors,\n",
    "        'Word2Vec': w2v_vectors,\n",
    "        'FastText': ft_vectors\n",
    "    }\n",
    "\n",
    "# 4. Comparison Summary\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"EMBEDDING COMPARISON (Feature Shapes)\")\n",
    "print(\"=\"*40)\n",
    "for ds_name, vectors in embedding_results.items():\n",
    "    print(f\"\\nDataset: {ds_name.upper()}\")\n",
    "    for model_name, data in vectors.items():\n",
    "        print(f\" - {model_name:10}: Shape {data.shape} (Rows, Features)\")"
   ],
   "id": "758ebe7b143b89aa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
